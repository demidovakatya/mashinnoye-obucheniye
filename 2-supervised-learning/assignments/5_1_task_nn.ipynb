{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронные сети: зависимость ошибки и обучающей способности от числа нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вы будете настраивать двуслойную нейронную сеть для решения задачи многоклассовой классификации. Предлагается выполнить процедуры загрузки и разбиения входных данных, обучения сети и подсчета ошибки классификации. Предлагается определить оптимальное количество нейронов в скрытом слое сети. Нужно так подобрать число нейронов, чтобы модель была с одной стороны несложной, а с другой стороны давала бы достаточно точный прогноз и не переобучалась. Цель задания -- показать, как зависит точность и обучающая способность сети от ее сложности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи многоклассовой классификации предлагается воспользоваться библиотекой построения нейронных сетей [pybrain](http://pybrain.org/). Библиотека содержит основные модули инициализации двуслойной нейронной сети прямого распространения, оценки ее параметров с помощью метода обратного распространения ошибки (backpropagation) и подсчета ошибки.\n",
    "\n",
    "Установить библиотеку pybrain можно с помощью стандартной системы управления пакетами pip:\n",
    "\n",
    "```\n",
    "pip install pybrain\n",
    "```\n",
    "Кроме того, для установки библиотеки можно использовать и другие способы, приведенные в [документации](https://github.com/pybrain/pybrain/wiki/installation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Используемые данные\n",
    "\n",
    "Рассматривается задача оценки качества вина по его физико-химическим свойствам [1]. Данные размещены в [открытом доступе](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv) в репозитории UCI  и содержат 1599 образцов красного вина, описанных 11 признаками, среди которых -- кислотность, процентное содержание сахара, алкоголя и пр. Кроме того, каждому объекту поставлена в соответствие оценка качества по шкале от 0 до 10. Требуется восстановить оценку качества вина по исходному признаковому описанию.\n",
    "\n",
    "[1] P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties.  In Decision Support Systems, Elsevier, 47(4):547-553, 2009. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Выполним инициализацию основных используемых модулей\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним загрузку данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('winequality-red.csv') as f:\n",
    "    f.readline()  # пропуск заголовочной строки\n",
    "    data = np.loadtxt(f, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве альтернативного варианта, можно выполнить загрузку данных напрямую из репозитория UCI, воспользовавшись библиотекой urllib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "# URL for the Wine Quality Data Set (UCI Machine Learning Repository)\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "# загрузка файла\n",
    "f = urllib.urlopen(url)\n",
    "f.readline()  # пропуск заголовочной строки\n",
    "data = np.loadtxt(f, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим из данных целевую переменную. Классы в задаче являются несбалинсированными: основной доле объектов поставлена оценка качества от 5 до 7. Приведем задачу к трехклассовой: объектам с оценкой качества меньше пяти поставим оценку 5, а объектам с оценкой качества больше семи поставим 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7 # Разделение данных на обучающую и контрольную части в пропорции 70/30%\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "y = data[:, -1]\n",
    "np.place(y, y < 5, 5)\n",
    "np.place(y, y > 7, 7)\n",
    "y -= min(y)\n",
    "X = data[:, :-1]\n",
    "X = normalize(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_SIZE, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Двуслойная нейронная сеть\n",
    "\n",
    "Двуслойная нейронная сеть представляет собой функцию распознавания, которая може быть записана в виде следующей суперпозиции:\n",
    "\n",
    "$f(x,W)=h^{(2)}\\left(\\sum\\limits_{i=1}^D w_i^{(2)}h^{(1)}\\left(\\sum\\limits_{j=1}^n w_{ji}^{(1)}x_j+b_i^{(1)}\\right)+b^{(2)}\\right)$, где\n",
    "\n",
    "$x$ -- исходный объект (сорт вина, описанный 11 признаками), $x_j$ -- соответствующий признак,\n",
    "\n",
    "$n$ --  количество нейронов во входном слое сети, совпадающее с количеством признаков,\n",
    "\n",
    "$D$ --  количество нейронов в скрытом слое сети,\n",
    "\n",
    "$w_i^{(2)}, w_{ji}^{(1)}, b_i^{(1)}, b^{(2)}$ --  параметры сети, соответствующие весам нейронов,\n",
    "\n",
    "$h^{(1)}, h^{(2)}$ -- функции активации.\n",
    "\n",
    "В качестве функции активации на скрытом слое сети используется линейная функция. На выходном слое сети используется функция активации softmax, являющаяся обобщением сигмоидной функции на многоклассовый случай:\n",
    "\n",
    "$y_k=\\text{softmax}_k(a_1,...,a_k)=\\frac{\\exp(a_k)}{\\sum_{k=1}^K\\exp(a_k)}.$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка параметров сети\n",
    "\n",
    "Оптимальные параметры сети $W_{opt}$ определяются путем минимизации функции ошибки:\n",
    "\n",
    "$W_{opt}=\\arg\\min\\limits_{W}L(W)+\\lambda\\|W\\|^2$.\n",
    "\n",
    "Здесь $L(W)$ является функцией ошибки многоклассовой классификации,\n",
    "\n",
    "$L(W)=- \\sum^N_{n=1}\\sum^K_{k=1} t_{kn} log(y_{kn}),$\n",
    "\n",
    "$t_{kn}$ -- бинарно закодированные метки классов, $K$ -- количество меток, $N$ -- количество объектов,\n",
    "\n",
    "а $\\lambda\\|W\\|^2$ является регуляризующим слагаемым, контролирующим суммарный вес параметров сети и предотвращающий эффект переобучения.\n",
    "\n",
    "Оптимизация параметров выполняется методом обратного распространения ошибки (backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним загрузку основных модулей: ClassificationDataSet -- структура данных pybrain, buildNetwork -- инициализация нейронной сети, BackpropTrainer -- оптимизация параметров сети методом backpropagation, SoftmaxLayer -- функция softmax, соответствующая выходному слою сети, percentError -- функцию подсчета ошибки классификации (доля неправильных ответов). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pybrain.datasets import ClassificationDataSet # Структура данных pybrain\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.structure.modules import SoftmaxLayer\n",
    "from pybrain.utilities import percentError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем основные параметры задачи: `HIDDEN_NEURONS_NUM` -- количество нейронов скрытого слоя, `MAX_EPOCHS` -- максимальное количество итераций алгоритма оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Определение основных констант\n",
    "HIDDEN_NEURONS_NUM = 100 # Количество нейронов, содержащееся в скрытом слое сети\n",
    "MAX_EPOCHS = 100 # Максимальное число итераций алгоритма оптимизации параметров сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем структуру данных `ClassificationDataSet`, используемую библиотекой `pybrain`. Для инициализации структура принимает два аргумента: количество признаков *np.shape(X)[1]* и количество различных меток классов *len(np.unique(y))*.\n",
    "\n",
    "Кроме того, произведем бинаризацию целевой переменной с помощью функции *_convertToOneOfMany( )* и разбиение данных на обучающую и контрольную части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Конвертация данных в структуру ClassificationDataSet\n",
    "# Обучающая часть\n",
    "ds_train = ClassificationDataSet(np.shape(X)[1], nb_classes=len(np.unique(y_train)))\n",
    "# Первый аргумент -- количество признаков np.shape(X)[1], второй аргумент -- количество меток классов len(np.unique(y_train)))\n",
    "ds_train.setField('input', X_train) # Инициализация объектов\n",
    "ds_train.setField('target', y_train[:, np.newaxis]) # Инициализация ответов; np.newaxis создает вектор-столбец\n",
    "ds_train._convertToOneOfMany( ) # Бинаризация вектора ответов\n",
    "# Контрольная часть\n",
    "ds_test = ClassificationDataSet(np.shape(X)[1], nb_classes=len(np.unique(y_train)))\n",
    "ds_test.setField('input', X_test)\n",
    "ds_test.setField('target', y_test[:, np.newaxis])\n",
    "ds_test._convertToOneOfMany( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем двуслойную сеть и произведем оптимизацию ее параметров. Аргументами для инициализации являются:\n",
    "\n",
    "ds.indim -- количество нейронов на входном слое сети, совпадает с количеством признаков (в нашем случае 11),\n",
    "\n",
    "HIDDEN_NEURONS_NUM -- количество нейронов в скрытом слое сети,\n",
    "\n",
    "ds.outdim -- количество нейронов на выходном слое сети, совпадает с количеством различных меток классов (в нашем случае 3),\n",
    "\n",
    "SoftmaxLayer -- функция softmax, используемая на выходном слое для решения задачи многоклассовой классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0) # Зафиксируем seed для получения воспроизводимого результата\n",
    "\n",
    "# Построение сети прямого распространения (Feedforward network)\n",
    "net = buildNetwork(ds_train.indim, HIDDEN_NEURONS_NUM, ds_train.outdim, outclass=SoftmaxLayer)\n",
    "# ds.indim -- количество нейронов входного слоя, равне количеству признаков\n",
    "# ds.outdim -- количество нейронов выходного слоя, равное количеству меток классов\n",
    "# SoftmaxLayer -- функция активации, пригодная для решения задачи многоклассовой классификации\n",
    "\n",
    "init_params = np.random.random((len(net.params))) # Инициализируем веса сети для получения воспроизводимого результата\n",
    "net._setParameters(init_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Выполним оптимизацию параметров сети. График ниже показывает сходимость функции ошибки на обучающей/контрольной части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "# Модуль настройки параметров pybrain использует модуль random\n",
    "# зафиксируем seed для получения воспроизводимого результата\n",
    "\n",
    "trainer = BackpropTrainer(net, dataset=ds_train) # Инициализируем модуль оптимизации\n",
    "err_train, err_val = trainer.trainUntilConvergence(maxEpochs=MAX_EPOCHS)\n",
    "\n",
    "line_train = plt.plot(err_train, 'b', err_val, 'r') # Построение графика\n",
    "xlab = plt.xlabel('Iterations')\n",
    "ylab = plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем значение доли неправильных ответов на обучающей и контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_train = net.activateOnDataset(ds_train).argmax(axis=1) # Подсчет результата на обучающей выборке\n",
    "print('Error on train: ', percentError(res_train, ds_train['target'].argmax(axis=1)), '%') # Подсчет ошибки\n",
    "\n",
    "res_test = net.activateOnDataset(ds_test).argmax(axis=1) # Подсчет результата на тестовой выборке\n",
    "print('Error on test: ', percentError(res_test, ds_test['target'].argmax(axis=1)), '%') # Подсчет ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание. Определение оптимального числа нейронов.\n",
    "В задании требуется исследовать зависимость ошибки на контрольной выборке в зависимости от числа нейронов в скрытом слое сети. Количество нейронов, по которому предполагается провести перебор, записано в векторе \n",
    "```\n",
    "hidden_neurons_num = [50, 100, 200, 500, 700, 1000]\n",
    "```\n",
    "\n",
    "1. Для фиксированного разбиения на обучающую и контрольную части подсчитайте долю неправильных ответов (ошибок) классификации на обучении/контроле в зависимости от количества нейронов в скрытом слое сети. Запишите результаты в массивы ```res_train_vec``` и ```res_test_vec```, соответственно. С помощью функции ```plot_classification_error``` постройте график зависимости ошибок на обучении/контроле от количества нейронов. Являются ли графики ошибок возрастающими/убывающими? При каком количестве нейронов достигается минимум ошибок классификации?\n",
    "\n",
    "2. С помощью функции ```write_answer_nn``` запишите в выходной файл число: количество нейронов в скрытом слое сети, для которого достигается минимум ошибки классификации на контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(0) # Зафиксируем seed для получния воспроизводимого результата\n",
    "np.random.seed(0)\n",
    "\n",
    "def plot_classification_error(hidden_neurons_num, res_train_vec, res_test_vec):\n",
    "# hidden_neurons_num -- массив размера h, содержащий количество нейронов, по которому предполагается провести перебор,\n",
    "#   hidden_neurons_num = [50, 100, 200, 500, 700, 1000];\n",
    "# res_train_vec -- массив размера h, содержащий значения доли неправильных ответов классификации на обучении;\n",
    "# res_train_vec -- массив размера h, содержащий значения доли неправильных ответов классификации на контроле\n",
    "    plt.figure()\n",
    "    plt.plot(hidden_neurons_num, res_train_vec)\n",
    "    plt.plot(hidden_neurons_num, res_test_vec, '-r')\n",
    "\n",
    "def write_answer_nn(optimal_neurons_num):\n",
    "    with open(\"nnets_answer1.txt\", \"w\") as fout:\n",
    "        fout.write(str(optimal_neurons_num))\n",
    "\n",
    "hidden_neurons_num = [50, 100, 200, 500, 700, 1000]\n",
    "res_train_vec = list()\n",
    "res_test_vec = list()\n",
    "\n",
    "for nnum in hidden_neurons_num:\n",
    "    # Put your code here\n",
    "    # Не забудьте про инициализацию весов командой np.random.random((len(net.params)))\n",
    "    \n",
    "# Постройте график зависимости ошибок на обучении и контроле в зависимости от количества нейронов\n",
    "plot_classification_error(hidden_neurons_num, res_train_vec, res_test_vec)          \n",
    "\n",
    "#  Запишите в файл количество нейронов, при котором достигается минимум ошибки на контроле\n",
    "write_answer_nn(hidden_neurons_num[res_test_vec.index(min(res_test_vec))]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
