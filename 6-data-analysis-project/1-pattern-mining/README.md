# <center> Идентификация пользователей по посещенным веб-страницам

В этом проекте мы будем решать задачу идентификации пользователя по его поведению в сети Интернет. Это сложная и интересная задача на стыке анализа данных и поведенческой психологии. В качестве примера, компания Яндекс решает задачу идентификации взломщика почтового ящика по его поведению. В двух словах, взломщик будет себя вести не так, как владелец ящика: он может не удалять сообщения сразу по прочтении, как это делал хозяин, он будет по-другому ставить флажки сообщениям и даже по-своему двигать мышкой. Тогда такого злоумышленника можно идентифицировать и "выкинуть" из почтового ящика, предложив хозяину войти по SMS-коду. Этот пилотный проект описан в [статье](https://habrahabr.ru/company/yandex/blog/230583/) на Хабрахабре. Похожие вещи делаются, например, в Google Analytics и описываются в научных статьях, найти можно многое по фразам "Traversal Pattern Mining" и "Sequential Pattern Mining".

<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>

Мы будем решать похожую задачу: по последовательности из нескольких веб-сайтов, посещенных подряд один и тем же человеком, мы будем идентифицировать этого человека. Идея такая: пользователи Интернета по-разному переходят по ссылкам, и это может помогать их идентифицировать (кто-то сначала в почту, потом про футбол почитать, затем новости, контакт, потом наконец – работать, кто-то – сразу работать).

Будем использовать данные из [статьи](http://ceur-ws.org/Vol-1058/) "A Tool for Classification of Sequential Data". И хотя мы не можем рекомендовать эту статью (описанные методы делеки от state-of-the-art, лучше обращаться к [книге](http://www.charuaggarwal.net/freqbook.pdf) "Frequent Pattern Mining" и последним статьям с ICDM), но данные там собраны аккуратно и представляют интерес.

Данные собраны с прокси-серверов Университета Блеза Паскаля и имеют очень простой вид: <br>

<center>ID пользователя, timestamp, посещенный веб-сайт</center>

Скачать исходные данные можно по [ссылке](http://fc.isima.fr/~kahngi/cez13.zip) в статье, там же описание.
Для этого задания хватит данных не по всем 3000 пользователям, а по 10 и 150. [Ссылка](https://yadi.sk/d/_HK76ZDo32AvNZ) на архив *capstone_websites_data.zip* (~7.1 Mb, в развернутом виде ~ 65 Mb). 

В ходе выполнения проекта вас ожидает 4 задания типа Programming Assignment, посвященных предобработке данных, первичному анализу, визуальному анализу данных, сравнению моделей классификации и настройке выбранной модели и изучению ее переобучения. Также у вас будет 3 взаимно оцениваемых задания (Peer Review) – по визуализации данных (в том числе со свеже созданными признаками), по оценке результатов участия в соревновании Kaggle Inclass и по всему проекту в целом.

## План проекта такой:

### 1 неделя. Подготовка данных к анализу и построению моделей. Programming Assignment

- Подготовка обучающей выборки
- Работа с разреженным форматом данных

### 2 неделя. Подготовка и первичный анализ данных. Programming Assignment

- Подготовка нескольких обучающих выборок для сравнения
- Первичный анализ данных, проверка гипотез

### 3 неделя. Визуальный анализ данных построение признаков. Peer-Review
- Визуальный анализ данных
- Построение признаков

### 4 неделя. Сравнение алгоритмов классификации. Programming Assignment
- Сравнение нескольких алгоритмов на сессиях из 10 сайтов
- Выбор параметров – длины сессии и ширины окна
- Идентификация конкретного пользователя и кривые обучения

### 5 неделя. Соревнование Kaggle Inclass по идентификации пользователей. Peer-Review

### 6 неделя. Vowpal Wabbit. Programming Assignment

- Тьюториал по Vowpal Wabbit
- Настройка параметров Vowpal Wabbit для большой выборки из 3000 пользователей
7 неделя. Оформление финального проекта. Peer-Review

### План 7 недели повторяет план всего проекта

В самом конце Вас ожидает взаимная проверка финальных версий проекта. Здесь можно будет разгуляться, поскольку свобода творчества есть на каждом этапе проекта: можно использовать все исходные данные по 3000 пользователям, можно создавать свои интересные признаки, строить красивые картинки, использовать свои модели или ансамбли моделей и делать выводы. Поэтому совет такой: по мере выполнения заданий параллельно копируйте код и описание в .ipynb-файл проекта или описывайте результаты по ходу в текстовом редакторе.